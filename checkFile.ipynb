{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-thickness",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\marku\\anaconda3\\envs\\final\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.tokens import Doc\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modified-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Äußerungen:  349\n",
      "# Annotationen:  349\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "annotations = []\n",
    "\n",
    "try:\n",
    "    fh = open(\"/Users/marku/Downloads/corpus_part_Deli.txt\", encoding=\"UTF-8\")\n",
    "    \n",
    "    for line_num, line_txt in enumerate(fh, start=1):\n",
    "        if line_num %2 == 1:\n",
    "            words.append(line_txt.strip())\n",
    "        else:\n",
    "            annotations.append(line_txt.strip())\n",
    "    fh.close()\n",
    "except IOError:\n",
    "    print(\"Could not read file\")\n",
    "\n",
    "print(\"# Äußerungen: \", len(words))\n",
    "print(\"# Annotationen: \", len(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dressed-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler in der Annotation bei folgenden Äußerungen:  []\n",
      "['B-Beurteilung,Bewertung,Gutachten,Wertung', 'B-Dauer', 'B-Ende,Endstück', 'B-Essen,Esswaren,Eßwaren,Lebensmittel,Nahrung,Nahrungsmittel,Speisen', 'B-Forum,Plattform', 'B-GemüseSahnesoße', 'B-Gericht:Gemüsesoße', 'B-Gericht:Sauce', 'B-Geschmacksträger', 'B-Gewürz', 'B-Kategorie:Aufläufe', 'B-Kategorie:Curry', 'B-Kategorie:Flüssigkeit', 'B-Kategorie:Gemüse', 'B-Kategorie:Gewürze', 'B-Kategorie:Kuchen', 'B-Kategorie:Milchprodukte', 'B-Kategorie:Pasta', 'B-Kategorie:Resteküche', 'B-Kategorie:Rezept', 'B-Kategorie:Rezepte', 'B-Kategorie:Rührei', 'B-Kategorie:Sahne', 'B-Kategorie:Sahnesauce', 'B-Kategorie:Salat', 'B-Kategorie:Sauce', 'B-Kategorie:Video', 'B-Kategorie:Zutaten', 'B-Knollen-Ziest', 'B-Kommentar,Kommentierung', 'B-Kraft', 'B-Liter,Maß', 'B-Menge', 'B-Menge:Brühe', 'B-Menge:Gramm', 'B-Menge:Milliliter', 'B-Menge:Personen', 'B-Menge:Zentimeter', 'B-Negation', 'B-Personen', 'B-Pfeffer', 'B-Punkt', 'B-Rezept', 'B-Rezept,Zubereitungsart', 'B-Rezept:Eier-in-Schinken-Sahne-Sauce', 'B-Rezept:Menge', 'B-Rezept:Sahne-Ei-Sauce', 'B-Rezept:Sauce', 'B-Rezept:Sauce,Hollandaise', 'B-Rezept:Sauce,zu,Spargel', 'B-Rezept:Spargelgratin', 'B-Sahnesauce,Sahnesoße', 'B-Sauce', 'B-Sauce,Sauce', 'B-Schritt', 'B-Spitze', 'B-Statistik', 'B-Stern', 'B-Volumen:Esslöffel,I:Volumen:Esslöffel', 'B-Volumen:bisschen', 'B-Webseite:Chefkoch', 'B-Zahlenspezifisch', 'B-Zeit', 'B-Zubereitung', 'B-Zubereitung:Abgießen', 'B-Zubereitung:Abgießen,abseihen', 'B-Zubereitung:Anbraten', 'B-Zubereitung:Butter', 'B-Zubereitung:Erhitzen', 'B-Zubereitung:Frittieren', 'B-Zubereitung:Füllen', 'B-Zubereitung:Hitze', 'B-Zubereitung:Kochen', 'B-Zubereitung:Kochen,Zutat:Wasser', 'B-Zubereitung:Kurz,Braten', 'B-Zubereitung:Löffel', 'B-Zubereitung:Pfanne', 'B-Zubereitung:Ruehren', 'B-Zubereitung:Rühren', 'B-Zubereitung:Salz', 'B-Zubereitung:Sauce', 'B-Zubereitung:Schale', 'B-Zubereitung:Schmelzen', 'B-Zubereitung:Schritte', 'B-Zubereitung:Schälen', 'B-Zubereitung:Stampfen', 'B-Zubereitung:Temperatur', 'B-Zubereitung:Topf', 'B-Zubereitung:Wasser', 'B-Zubereitung:Wasserbad', 'B-Zubereitung:Würfeln', 'B-Zubereitung:Zerlassen', 'B-Zubereitung:Ziehen,lassen', 'B-Zubereitung:Zucchini', 'B-Zubereitung:abschälen', 'B-Zubereitung:abwaschen', 'B-Zubereitung:anbraten', 'B-Zubereitung:anmachen', 'B-Zubereitung:aufgießen', 'B-Zubereitung:aufkochen', 'B-Zubereitung:braten', 'B-Zubereitung:heißt,sagen,steht', 'B-Zubereitung:hinzufügen', 'B-Zubereitung:kochen', 'B-Zubereitung:lassen/stehen', 'B-Zubereitung:machen', 'B-Zubereitung:machen/,tun', 'B-Zubereitung:muss', 'B-Zubereitung:müssen', 'B-Zubereitung:nehmen', 'B-Zubereitung:reinschmeißen,hinzugeben', 'B-Zubereitung:reintun', 'B-Zubereitung:roh', 'B-Zubereitung:rühren', 'B-Zubereitung:schauen', 'B-Zubereitung:schauen,I:Zubereitung:schauen', 'B-Zubereitung:schneiden', 'B-Zubereitung:schälen', 'B-Zubereitung:stellen', 'B-Zubereitung:ungekocht', 'B-Zubereitung:vermischen,mischen,vermengen', 'B-Zubereitung:verwenden', 'B-Zubereitung:weglassen', 'B-Zubereitung:zugeben/geben', 'B-Zubereitung:zuschneiden', 'B-Zustand:sein', 'B-Zutat', 'B-Zutat:Bitterstoffe', 'B-Zutat:Brokoli', 'B-Zutat:Brühe', 'B-Zutat:Bulgur', 'B-Zutat:Butter', 'B-Zutat:Cayenne-Pfeffer', 'B-Zutat:Cayennepfeffer', 'B-Zutat:Couscous', 'B-Zutat:Creme', 'B-Zutat:Crème,fraîche', 'B-Zutat:Ei', 'B-Zutat:Ei,Eier', 'B-Zutat:Eigelb', 'B-Zutat:Eimasse', 'B-Zutat:Gemüse', 'B-Zutat:Gemüsebrühe', 'B-Zutat:Gurke', 'B-Zutat:Kartoffel', 'B-Zutat:Kichererbse', 'B-Zutat:Kichererbsen', 'B-Zutat:Kidney', 'B-Zutat:Kidneybohnen', 'B-Zutat:Knoblauch', 'B-Zutat:Kokosmilch', 'B-Zutat:Kopf', 'B-Zutat:Lachs', 'B-Zutat:Mehl', 'B-Zutat:Milch', 'B-Zutat:Mozzarella', 'B-Zutat:Muskat,Muskatnuss', 'B-Zutat:Nudeln', 'B-Zutat:Olivenöl', 'B-Zutat:Orangensaft', 'B-Zutat:Paprika', 'B-Zutat:Paprikapulver', 'B-Zutat:Pesto', 'B-Zutat:Pfeffer', 'B-Zutat:Rühreier', 'B-Zutat:Sahne', 'B-Zutat:Salz', 'B-Zutat:Sauerrahm,saure,Sahne', 'B-Zutat:Schinken', 'B-Zutat:Schlagsahne', 'B-Zutat:Schmand', 'B-Zutat:Spargel', 'B-Zutat:Tomate', 'B-Zutat:Tomaten', 'B-Zutat:Wasser', 'B-Zutat:Weißwein', 'B-Zutat:Zitronensaft', 'B-Zutat:Zucchini', 'B-Zutat:Zucker', 'B-Zutat:unbekannt', 'B-Zutat:weißer-Spargel', 'B-Zutat:Öl', 'B-Zutaten', 'B-ablöschen,aufgießen', 'B-abschneiden,absäbeln,schneiden', 'B-akzeptiert,angenommen', 'B-anbraten', 'B-andünsten,dünsten', 'B-aufbewahren,bewahren,verwahren', 'B-aufeinanderfolgen,folgen,kommen', 'B-auslassen,aussparen,weglassen', 'B-befinden,sein', 'B-befördern,transportieren', 'B-beginnen', 'B-belassen,lassen', 'B-benutzen,benützen,brauchen,gebrauchen,verwenden', 'B-beschreiben', 'B-bewilligen,billigen,goutieren,zustimmen,gutheißen', 'B-bleiben', 'B-brauchbar,nutzbar', 'B-brauchen', 'B-da,sein,dasein,existieren', 'B-divers,ungleich,ungleichartig,verschieden,verschiedenartig', 'B-drücken', 'B-entdecken,finden,vorfinden', 'B-erschafen,machen,schaffen', 'B-erschaffen,machen,schaffen', 'B-erstrecken', 'B-extra,gesondert,getrennt,separat', 'B-festhalten', 'B-fett', 'B-feuchtigkeitsspezifisch', 'B-fit', 'B-funktionieren,gehen', 'B-gebühren,gehören,geziemen,schicken,ziemen', 'B-gehen,möglich,sein', 'B-gehören', 'B-gucken,kucken,schauen', 'B-haltbar,machen,konservieren,präservieren', 'B-hervorbringen,machen,produzieren,schaffen', 'B-hineinkommen,reinkommen', 'B-kalorienarm', 'B-kilogram', 'B-kochen,sieden', 'B-kommen', 'B-komplett,vollständig,vollzählig', 'B-kurz,kurzzeitig', 'B-könne', 'B-können', 'B-machen,tun', 'B-materielle,Zustandsveränderung', 'B-meinen', 'B-meinen,sagen,äußern', 'B-mengen,vermengen,vermischen,zusammenmischen', 'B-mengenspezifisch', 'B-mengenspezifisch,Gramm', 'B-mengenspezifisch,Person', 'B-mengenspezifisch:viel', 'B-mengenspezisfisch', 'B-mischen', 'B-müssen', 'B-nachgucken,nachkucken,nachprüfen,nachschauen,nachsehen,überprüfen', 'B-negativ', 'B-negieren,verneinen', 'B-ortsspezifisch', 'B-pinch', 'B-positiv', 'B-positiv,steigerungsspezifisch', 'B-quanitiätsspezifisch', 'B-quantitaetsspezifisch', 'B-rechnen,ermitteln', 'B-reduzieren,mindern,vermindern,verringern', 'B-sagen', 'B-schauen', 'B-schwemmen,waschen', 'B-sein', 'B-suchen,entdecken,finden', 'B-suchen,entdecken,finden,vorfinden', 'B-temperaturspezifisch', 'B-treffen,widerfahren,zustoßen', 'B-vergangen', 'B-vergessen', 'B-vergrößern', 'B-verzehren', 'B-vollständigkeitsspezifisch,zeitspezifisch', 'B-vorlesen,lesen,sprechen', 'B-vorschlagen', 'B-vorzeigen,zeigen', 'B-zahlenenspezifisch', 'B-zahlenenspezifisch:gram', 'B-zahlenspezifisch', 'B-zahlenspezifisch,Gramm', 'B-zahlenspezifisch,Kochzeit', 'B-zahlenspezifisch,Person', 'B-zahlenspezifisch,g', 'B-zahlenspezifisch,gram', 'B-zahlespezifisch', 'B-zeitspezifisch', 'B-zusammenbleiben', 'B-ätherisches,Öl', 'I-Beurteilung,Bewertung,Gutachten,Wertung', 'I-Dauer', 'I-Ende,Endstück', 'I-Essen,Esswaren,Eßwaren,Lebensmittel,Nahrung,Nahrungsmittel,Speisen', 'I-Geschmacksträger', 'I-Kategorie:Aufläufe', 'I-Kategorie:Curry', 'I-Kategorie:Flüssigkeit', 'I-Kategorie:Gemüse', 'I-Kategorie:Gewürze', 'I-Kategorie:Rezept', 'I-Kategorie:Rezepte', 'I-Kategorie:Rührei', 'I-Kategorie:Sahnesauce', 'I-Kategorie:Salat', 'I-Kategorie:Sauce', 'I-Kategorie:Video', 'I-Kommentar,Kommentierung', 'I-Menge', 'I-Menge:Brühe', 'I-Menge:Gramm', 'I-Menge:Milliliter', 'I-Menge:Personen', 'I-Menge:Zentimeter', 'I-Portion', 'I-Rezept', 'I-Rezept,Zubereitungsart', 'I-Rezept:Eier-in-Schinken-Sahne-Sauce', 'I-Rezept:Menge', 'I-Rezept:Sahne-Ei-Sauce', 'I-Rezept:Sauce', 'I-Rezept:Sauce,Hollandaise', 'I-Rezept:Spargelgratin', 'I-Schritt', 'I-Spitze', 'I-Stern', 'I-Stunde', 'I-Zahlenspezifisch', 'I-Zeit', 'I-Zubereitung', 'I-Zubereitung:Abgießen,abseihen', 'I-Zubereitung:Anbraten', 'I-Zubereitung:Erhitzen', 'I-Zubereitung:Frittieren', 'I-Zubereitung:Füllen', 'I-Zubereitung:Kochen', 'I-Zubereitung:Kochen,Zutat:Wasser', 'I-Zubereitung:Kurz,Braten', 'I-Zubereitung:Pfanne', 'I-Zubereitung:Ruehren', 'I-Zubereitung:Schale', 'I-Zubereitung:Schmelzen', 'I-Zubereitung:Schritte', 'I-Zubereitung:Schälen', 'I-Zubereitung:Stampfen', 'I-Zubereitung:Temperatur', 'I-Zubereitung:Topf', 'I-Zubereitung:Wasser', 'I-Zubereitung:Wasserbad', 'I-Zubereitung:Ziehen,lassen', 'I-Zubereitung:abschälen', 'I-Zubereitung:anbraten', 'I-Zubereitung:aufgießen', 'I-Zubereitung:aufkochen', 'I-Zubereitung:hinzufügen', 'I-Zubereitung:kochen', 'I-Zubereitung:kochen,sieden', 'I-Zubereitung:lassen/stehen', 'I-Zubereitung:muss', 'I-Zubereitung:schauen', 'I-Zubereitung:schneiden', 'I-Zubereitung:schälen', 'I-Zubereitung:stechen', 'I-Zubereitung:waschen', 'I-Zutat', 'I-Zutat-Schinken', 'I-Zutat:Brühe', 'I-Zutat:Bulgur', 'I-Zutat:Butter', 'I-Zutat:Couscous', 'I-Zutat:Crème,fraîche', 'I-Zutat:Eigelb', 'I-Zutat:Gemüse', 'I-Zutat:Gurke', 'I-Zutat:Gurke,dass,man,da,so', 'I-Zutat:Kartoffel', 'I-Zutat:Kichererbsen', 'I-Zutat:Kidney', 'I-Zutat:Kopf', 'I-Zutat:Lachs', 'I-Zutat:Nudeln', 'I-Zutat:Orangensaft', 'I-Zutat:Paprika', 'I-Zutat:Sahne', 'I-Zutat:Salz', 'I-Zutat:Sauerrahm,saure,Sahne', 'I-Zutat:Schmand', 'I-Zutat:Spargel', 'I-Zutat:Tomate', 'I-Zutat:Wasser', 'I-Zutat:Zucker', 'I-Zutat:fraiche', 'I-Zutat:weißer-Spargel', 'I-ablöschen,aufgießen', 'I-akzeptiert,angenommen', 'I-andünsten,dünsten', 'I-anrichten,zubereiten', 'I-aufbewahren,bewahren,verwahren', 'I-brauchbar,nutzbar', 'I-brauchen', 'I-entfernen', 'I-erschaffen,machen,schaffen', 'I-feuchtigkeitsspezifisch', 'I-gehören', 'I-haben', 'I-haltbar,machen,konservieren,präservieren', 'I-heiß', 'I-hervorbringen,machen,produzieren,schaffen', 'I-hineinkommen,reinkommen', 'I-kochen,sieden', 'I-kommen', 'I-können', 'I-machen,tun', 'I-materielle,Zustandsveränderung', 'I-meinen', 'I-meinen,sagen,äußern', 'I-mengen,vermengen,vermischen,zusammenmischen', 'I-mengenspezifisch,Gramm', 'I-mengenspezifisch,Person', 'I-mengenspezifisch:viel', 'I-positiv,steigerungsspezifisch', 'I-quantitaetsspezifisch', 'I-sagen', 'I-schauen', 'I-schauen,bei', 'I-springen', 'I-sprudeln', 'I-suchen,entdecken,finden,vorfinden', 'I-sämig', 'I-treffen,widerfahren,zustoßen', 'I-unterwegs', 'I-vergangen', 'I-vergessen', 'I-vergrößern', 'I-vollständigkeitsspezifisch,zeitspezifisch', 'I-zahlenspezifisch', 'I-zahlenspezifisch,Gramm', 'I-zahlenspezifisch,Person', 'I-zahlenspezifisch,g', 'I-zahlenspezifisch,gram', 'I-zeitspezifisch', 'I-zuschneiden', 'I:Zutat:fraiche', 'O', 'min']\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "incorrect_annotations = []\n",
    "doc_id = 0\n",
    "annotations_in_use = \"\"\n",
    "initial_tags = []\n",
    "\n",
    "for doc in nlp.pipe(words):\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        tokens.append(token.lemma_)\n",
    "    tags = annotations[doc_id].split()\n",
    "    initial_tags.append(tags[0])\n",
    "    if len(tokens) == len(tags):\n",
    "        for t in range(len(tokens)):\n",
    "            text.append(tokens[t].lower() + \" \" + tags[t])\n",
    "            annotations_in_use = annotations_in_use + \" \" + annotations[doc_id]\n",
    "    else:\n",
    "        print(2*(doc_id+1), len(tokens), len(tags))\n",
    "        incorrect_annotations.append(doc_id)\n",
    "    doc_id = doc_id + 1\n",
    "print(\"Fehler in der Annotation bei folgenden Äußerungen: \", incorrect_annotations)\n",
    "print(sorted(set(annotations_in_use.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "monetary-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsLemma = []\n",
    "for doc in nlp.pipe(words):\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        tokens.append(token.lemma_.lower())\n",
    "    wordsLemma.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "closing-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "countSentence = 0\n",
    "for sentence in wordsLemma:\n",
    "    countElement = 0\n",
    "    anno = re.sub(':[A-Z|a-z|0-9|ä|ü|ö|ß]*', '', annotations[countSentence]).split()\n",
    "    for element in sentence:\n",
    "        tuples = []\n",
    "        tuples.append(countSentence)\n",
    "        tuples.append(element)\n",
    "        tuples.append(anno[countElement])\n",
    "        countElement += 1\n",
    "        dataset.append(tuples)\n",
    "    countSentence += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "absolute-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceLengthList = []\n",
    "count = 0\n",
    "lastNumber = 0\n",
    "for element in dataset:\n",
    "    if(element[0] == lastNumber):\n",
    "        count += 1\n",
    "    else:\n",
    "        sentenceLengthList.append(count)\n",
    "        count = 1\n",
    "        lastNumber += 1\n",
    "sentenceLengthList.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unique-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSentenceLength = 50 #Post Padding auf Satzlänge 50\n",
    "newDataset = []\n",
    "countSentence = 0\n",
    "countIndex = 0\n",
    "count = 0\n",
    "for liste in sentenceLengthList:\n",
    "    for i in range(maxSentenceLength):\n",
    "        tuples = []\n",
    "        if  i < liste:\n",
    "            tuples.append(countSentence)\n",
    "            tuples.append(dataset[count][1])\n",
    "            tuples.append(dataset[count][2])\n",
    "            newDataset.append(tuples)\n",
    "            count += 1\n",
    "        else:\n",
    "            tuples.append(countSentence)\n",
    "            tuples.append('PADword')\n",
    "            tuples.append('O')\n",
    "            newDataset.append(tuples)\n",
    "    countSentence += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "external-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame (newDataset, columns=['Sentence', 'Word', 'Annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collect-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 #Anlegen einer Liste mit den X-Werten\n",
    "listX = []\n",
    "tmp = []\n",
    "for i in range (len(df['Word'])): \n",
    "    if count < maxSentenceLength:\n",
    "        tmp.append(newDataset[i][1])\n",
    "    else:\n",
    "        count = 0\n",
    "        listX.append(tmp)\n",
    "        tmp = []\n",
    "        tmp.append(newDataset[i][1])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imperial-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 #Anlegen einer Liste mit den Y-Werten\n",
    "listY = []\n",
    "tmp = []\n",
    "for i in range (len(df['Annotation'])): \n",
    "    if count < maxSentenceLength:\n",
    "        tmp.append(newDataset[i][2])\n",
    "    else:\n",
    "        count = 0\n",
    "        listY.append(tmp)\n",
    "        tmp = []\n",
    "        tmp.append(newDataset[i][2])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rental-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = [] #Neues Dataset da nun nur noch Values von Tag\n",
    "countSentence = 0\n",
    "for sentence in wordsLemma:\n",
    "    countElement = 0\n",
    "    anno = re.sub('[A-Z]-[A-Z|a-z|-|ä|Ä|ü|Ü|ö|ö|ß|,|0-9]*:', '', annotations[countSentence]).split()\n",
    "    for element in sentence:\n",
    "        tuples = []\n",
    "        tuples.append(countSentence)\n",
    "        tuples.append(element)\n",
    "        tuples.append(anno[countElement])\n",
    "        countElement += 1\n",
    "        dataset2.append(tuples)\n",
    "    countSentence += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "valuable-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = [] #Tags ohne Value durch 'O' ersetzen\n",
    "for liste in dataset2:\n",
    "    tmp2 = []\n",
    "    for element in liste:\n",
    "        if isinstance(element, str):\n",
    "            if element.startswith('B-'):\n",
    "                tmp2.append('O')\n",
    "            elif element.startswith('I-'):\n",
    "                tmp2.append('O')\n",
    "            else:\n",
    "                tmp2.append(element)\n",
    "        else:\n",
    "            tmp2.append(element)\n",
    "    tmp1.append(tmp2)\n",
    "dataset2 = tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "knowing-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSentenceLength = 50 #Post Padding\n",
    "newDataset2 = []\n",
    "countSentence = 0\n",
    "countIndex = 0\n",
    "count = 0\n",
    "for liste in sentenceLengthList:\n",
    "    for i in range(maxSentenceLength):\n",
    "        tuples = []\n",
    "        if  i < liste:\n",
    "            tuples.append(countSentence)\n",
    "            tuples.append(dataset2[count][1])\n",
    "            tuples.append(dataset2[count][2])\n",
    "            newDataset2.append(tuples)\n",
    "            count += 1\n",
    "        else:\n",
    "            tuples.append(countSentence)\n",
    "            tuples.append('PADword')\n",
    "            tuples.append('O')\n",
    "            newDataset2.append(tuples) \n",
    "    countSentence += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "animated-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = DataFrame (newDataset2, columns=['Sentence', 'Word', 'Annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baking-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 #Anlegen einer Liste mit den X-Werten\n",
    "listX2 = []\n",
    "tmp = []\n",
    "for i in range (len(df2['Word'])): \n",
    "    if count < maxSentenceLength:\n",
    "        tmp.append(newDataset2[i][1])\n",
    "    else:\n",
    "        count = 0\n",
    "        listX2.append(tmp)\n",
    "        tmp = []\n",
    "        tmp.append(newDataset2[i][1])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "absolute-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 #Anlegen einer Liste mit den Y-Werten\n",
    "listY2 = []\n",
    "tmp = []\n",
    "for i in range (len(df2['Annotation'])): \n",
    "    if count < maxSentenceLength:\n",
    "        tmp.append(newDataset2[i][2])\n",
    "    else:\n",
    "        count = 0\n",
    "        listY2.append(tmp)\n",
    "        tmp = []\n",
    "        tmp.append(newDataset2[i][2])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eleven-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(listX), np.array(listY), test_size=0.1, random_state=420)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(np.array(listX2), np.array(listY2), test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "english-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNotIncludeds(TrainList, TestList):\n",
    "    tmp = []\n",
    "    tmp2 = []\n",
    "    result = []\n",
    "    for liste in TrainList:\n",
    "        for element in liste:\n",
    "            if element != 'O':\n",
    "                tmp.append(element)\n",
    "    for liste in TestList:\n",
    "        for element in liste:\n",
    "            if element != 'O':\n",
    "                tmp2.append(element)\n",
    "    tmp = (list(set(tmp)))\n",
    "    tmp2 = (list(set(tmp2)))\n",
    "    for element in tmp2:\n",
    "        if (element in tmp) == False:\n",
    "            result.append(element)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "romantic-operator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-treffen,widerfahren,zustoßen', 'B-Pfeffer', 'I-Zutat-Schinken', 'B-Zubereitung,mischen,vermengen', 'B-Zutat-Spargel', 'B-verzehren', 'B-komplett,vollständig,vollzählig', 'I-Zutat-Spargel', 'B-gehören', 'B-vorschlagen', 'B-temperaturspezifisch', 'B-schauen', 'I-entfernen', 'B-Statistik', 'B-treffen,widerfahren,zustoßen', 'I-gehören', 'B-Zutat,Muskatnuss']\n"
     ]
    }
   ],
   "source": [
    "print(checkNotIncludeds(y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thrown-strike",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weglassen', 'roh', 'Schritte', 'Tomaten', 'ungekocht', 'Milch', 'weißer-Spargel']\n"
     ]
    }
   ],
   "source": [
    "print(checkNotIncludeds(y_train2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-insulin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
